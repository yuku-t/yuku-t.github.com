(window.webpackJsonp=window.webpackJsonp||[]).push([[10],{386:function(e,a,t){__NEXT_REGISTER_PAGE("/blog/2019/01/hello-pyspark",function(){return e.exports=t(399),{page:e.exports.default}})},399:function(e,a,t){"use strict";t.r(a);var l=t(6),n=t.n(l),r=t(0),c=t.n(r),s=t(20),m=function(){return c.a.createElement("div",null,c.a.createElement("div",{className:"cell border-box-sizing text_cell rendered"},c.a.createElement("div",{className:"prompt input_prompt"}),c.a.createElement("div",{className:"inner_cell"},c.a.createElement("div",{className:"text_cell_render border-box-sizing rendered_html"},c.a.createElement("p",null,c.a.createElement("a",{href:"https://spark.apache.org"},"Apatch Spark")," は JVM 上に実装されたオープンソースの分散処理プログラミング環境で、",c.a.createElement("a",{href:"http://fortune.com/2015/09/25/apache-spark-survey/"},"近年急速な盛り上がりを見せています"),"。 今後 ",c.a.createElement("a",{href:"https://spark.apache.org/docs/latest/api/python/index.html"},"pyspark")," を通じて Spark を使う予定なので、試しに触ってみたいのですが、いかんせん JVM に慣れていないこともあって Spark のインストールから始めると大変です。"),c.a.createElement("p",null,"そこでこの記事では Docker を使って Spark と pyspark の環境を構築します。"),c.a.createElement("h2",{id:"環境を用意する"},"環境を用意する",c.a.createElement("a",{className:"anchor-link",href:"#環境を用意する"},"¶")),c.a.createElement("p",null,"Jupyter Lab が公開している ",c.a.createElement("a",{href:"https://hub.docker.com/r/jupyter/pyspark-notebook/"},"jupyter/pyspark-notebook")," というズバリな Docker イメージがあるのでこれを使います。さしあたり現時点で公開されている最新版（",c.a.createElement("code",null,"87210526f381"),"）を指定する docker-compose.yml を用意しました:"),c.a.createElement("div",{className:"highlight"},c.a.createElement("pre",null,c.a.createElement("span",null),c.a.createElement("span",{className:"nt"},"version"),c.a.createElement("span",{className:"p"},":")," ",c.a.createElement("span",{className:"s"},'"3"'),"\n",c.a.createElement("span",{className:"nt"},"services"),c.a.createElement("span",{className:"p"},":"),"\n","  ",c.a.createElement("span",{className:"nt"},"notebook"),c.a.createElement("span",{className:"p"},":"),"\n","    ",c.a.createElement("span",{className:"nt"},"image"),c.a.createElement("span",{className:"p"},":")," ",c.a.createElement("span",{className:"l l-Scalar l-Scalar-Plain"},"jupyter/pyspark-notebook:87210526f381"),"\n","    ",c.a.createElement("span",{className:"nt"},"working_dir"),c.a.createElement("span",{className:"p"},":")," ",c.a.createElement("span",{className:"l l-Scalar l-Scalar-Plain"},"/app/notebooks"),"\n","    ",c.a.createElement("span",{className:"nt"},"ports"),c.a.createElement("span",{className:"p"},":"),"\n","      ",c.a.createElement("span",{className:"p p-Indicator"},"-")," ",c.a.createElement("span",{className:"l l-Scalar l-Scalar-Plain"},"8888:8888"),"\n","    ",c.a.createElement("span",{className:"nt"},"volumes"),c.a.createElement("span",{className:"p"},":"),"\n","      ",c.a.createElement("span",{className:"p p-Indicator"},"-")," ",c.a.createElement("span",{className:"l l-Scalar l-Scalar-Plain"},"./notebooks:/app/notebooks"),"\n","      ",c.a.createElement("span",{className:"p p-Indicator"},"-")," ",c.a.createElement("span",{className:"l l-Scalar l-Scalar-Plain"},"./data:/app/data"),"\n")),c.a.createElement("p",null,"2 つのディレクトリをマウントしています:"),c.a.createElement("ul",null,c.a.createElement("li",null,c.a.createElement("code",null,"./notebooks")," - Jupyter Notebook を保存するディレクトリ。作った Notebook を Docker の外に持ち出す目的でマウントしています。"),c.a.createElement("li",null,c.a.createElement("code",null,"./data")," - 分析用のデータを格納するディレクトリです。今回の記事では使っていませんが、 CSV ファイルなどをここにおいて Jupyter から触れるようにします。")),c.a.createElement("p",null,"用意ができたら ",c.a.createElement("code",null,"docker-compse up")," を実行して起動します。すると何やらログが表示される中に URL が表示されるので、その URL にアクセスすれば pyspark が使える Jupyter Notebook が表示されます。簡単ですね。")))),c.a.createElement("div",{className:"cell border-box-sizing code_cell rendered"},c.a.createElement("div",{className:"input"},c.a.createElement("div",{className:"prompt input_prompt"},"In [1]:"),c.a.createElement("div",{className:"inner_cell"},c.a.createElement("div",{className:"input_area"},c.a.createElement("div",{className:" highlight hl-ipython3"},c.a.createElement("pre",null,c.a.createElement("span",null),c.a.createElement("span",{className:"kn"},"import")," ",c.a.createElement("span",{className:"nn"},"pyspark"),"\n",c.a.createElement("span",{className:"n"},"pyspark"),c.a.createElement("span",{className:"o"},"."),c.a.createElement("span",{className:"n"},"version"),c.a.createElement("span",{className:"o"},"."),c.a.createElement("span",{className:"n"},"__version__"),"\n"))))),c.a.createElement("div",{className:"output_wrapper"},c.a.createElement("div",{className:"output"},c.a.createElement("div",{className:"output_area"},c.a.createElement("div",{className:"prompt output_prompt"},"Out[1]:"),c.a.createElement("div",{className:"output_text output_subarea output_execute_result"},c.a.createElement("pre",null,"'2.4.0'")))))),c.a.createElement("div",{className:"cell border-box-sizing text_cell rendered"},c.a.createElement("div",{className:"prompt input_prompt"}),c.a.createElement("div",{className:"inner_cell"},c.a.createElement("div",{className:"text_cell_render border-box-sizing rendered_html"},c.a.createElement("p",null,"ちなみにこの記事はまさにこうして起動した Jupyter Notebook を使って書かれています。"),c.a.createElement("h2",{id:"Spark-クラスタを起動する"},"Spark クラスタを起動する",c.a.createElement("a",{className:"anchor-link",href:"#Spark-クラスタを起動する"},"¶")),c.a.createElement("p",null,"Spark は通常クラスタを作って分散処理を行いますが、開発段階からクラスタを作るのは大変なので ",c.a.createElement("a",{href:"https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-local.html"},"local mode")," が用意されています。"),c.a.createElement("p",null,"pyspark から local mode で Spark を起動するには ",c.a.createElement("a",{href:"https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.SparkContext"},c.a.createElement("code",null,"pyspark.SparkContext"))," を実行します:")))),c.a.createElement("div",{className:"cell border-box-sizing code_cell rendered"},c.a.createElement("div",{className:"input"},c.a.createElement("div",{className:"prompt input_prompt"},"In [2]:"),c.a.createElement("div",{className:"inner_cell"},c.a.createElement("div",{className:"input_area"},c.a.createElement("div",{className:" highlight hl-ipython3"},c.a.createElement("pre",null,c.a.createElement("span",null),c.a.createElement("span",{className:"n"},"sc")," ",c.a.createElement("span",{className:"o"},"=")," ",c.a.createElement("span",{className:"n"},"pyspark"),c.a.createElement("span",{className:"o"},"."),c.a.createElement("span",{className:"n"},"SparkContext"),c.a.createElement("span",{className:"p"},"("),c.a.createElement("span",{className:"s1"},"'local[*]'"),c.a.createElement("span",{className:"p"},")"),"\n")))))),c.a.createElement("div",{className:"cell border-box-sizing text_cell rendered"},c.a.createElement("div",{className:"prompt input_prompt"}),c.a.createElement("div",{className:"inner_cell"},c.a.createElement("div",{className:"text_cell_render border-box-sizing rendered_html"},c.a.createElement("p",null,"渡している文字列は利用可能スレッド数を意味していて:"),c.a.createElement("ul",null,c.a.createElement("li",null,c.a.createElement("code",null,"local")," - 1 スレッドのみ使う"),c.a.createElement("li",null,c.a.createElement("code",null,"local[n]")," - ",c.a.createElement("code",null,"n")," スレッド使う（",c.a.createElement("code",null,"n")," は実際には数字が入る）"),c.a.createElement("li",null,c.a.createElement("code",null,"local[*]")," - JVM で使えるプロセッサーの数だけスレッドを使う（内部では ",c.a.createElement("a",{href:"https://docs.oracle.com/javase/8/docs/api/java/lang/Runtime.html#availableProcessors--"},c.a.createElement("code",null,"Runtime.getRuntime.availableProcessors()"))," を使っているらしい）")),c.a.createElement("p",null,"ということを表しています。一般的には ",c.a.createElement("code",null,"local[*]")," が使われるようです。"),c.a.createElement("p",null,"試しに 0 から 10 までの数字の合計を計算してみます。")))),c.a.createElement("div",{className:"cell border-box-sizing code_cell rendered"},c.a.createElement("div",{className:"input"},c.a.createElement("div",{className:"prompt input_prompt"},"In [3]:"),c.a.createElement("div",{className:"inner_cell"},c.a.createElement("div",{className:"input_area"},c.a.createElement("div",{className:" highlight hl-ipython3"},c.a.createElement("pre",null,c.a.createElement("span",null),c.a.createElement("span",{className:"n"},"rdd")," ",c.a.createElement("span",{className:"o"},"=")," ",c.a.createElement("span",{className:"n"},"sc"),c.a.createElement("span",{className:"o"},"."),c.a.createElement("span",{className:"n"},"parallelize"),c.a.createElement("span",{className:"p"},"("),c.a.createElement("span",{className:"nb"},"range"),c.a.createElement("span",{className:"p"},"("),c.a.createElement("span",{className:"mi"},"10"),c.a.createElement("span",{className:"p"},"))"),"\n",c.a.createElement("span",{className:"n"},"rdd"),c.a.createElement("span",{className:"o"},"."),c.a.createElement("span",{className:"n"},"sum"),c.a.createElement("span",{className:"p"},"()"),"\n"))))),c.a.createElement("div",{className:"output_wrapper"},c.a.createElement("div",{className:"output"},c.a.createElement("div",{className:"output_area"},c.a.createElement("div",{className:"prompt output_prompt"},"Out[3]:"),c.a.createElement("div",{className:"output_text output_subarea output_execute_result"},c.a.createElement("pre",null,"45")))))),c.a.createElement("div",{className:"cell border-box-sizing text_cell rendered"},c.a.createElement("div",{className:"prompt input_prompt"}),c.a.createElement("div",{className:"inner_cell"},c.a.createElement("div",{className:"text_cell_render border-box-sizing rendered_html"},c.a.createElement("p",null,"使い終わったら停止します。")))),c.a.createElement("div",{className:"cell border-box-sizing code_cell rendered"},c.a.createElement("div",{className:"input"},c.a.createElement("div",{className:"prompt input_prompt"},"In [4]:"),c.a.createElement("div",{className:"inner_cell"},c.a.createElement("div",{className:"input_area"},c.a.createElement("div",{className:" highlight hl-ipython3"},c.a.createElement("pre",null,c.a.createElement("span",null),c.a.createElement("span",{className:"n"},"sc"),c.a.createElement("span",{className:"o"},"."),c.a.createElement("span",{className:"n"},"stop"),c.a.createElement("span",{className:"p"},"()"),"\n")))))),c.a.createElement("div",{className:"cell border-box-sizing text_cell rendered"},c.a.createElement("div",{className:"prompt input_prompt"}),c.a.createElement("div",{className:"inner_cell"},c.a.createElement("div",{className:"text_cell_render border-box-sizing rendered_html"},c.a.createElement("h2",{id:"おわりに"},"おわりに",c.a.createElement("a",{className:"anchor-link",href:"#おわりに"},"¶")),c.a.createElement("p",null,"この記事では Docker を使って pyspark 環境を作り、実際に Spark クラスタを起動してみました。Spark のことはまだまだ全然分かりませんが少しずつできることを増やしていこうと思います。"),c.a.createElement("h2",{id:"参考"},"参考",c.a.createElement("a",{className:"anchor-link",href:"#参考"},"¶")),c.a.createElement("ul",null,c.a.createElement("li",null,c.a.createElement("a",{href:"https://hub.docker.com/r/jupyter/pyspark-notebook/"},"jupyter/pyspark-notebook - Docker Hub")),c.a.createElement("li",null,c.a.createElement("a",{href:"https://jupyter-docker-stacks.readthedocs.io/en/latest/using/specifics.html#apache-spark"},"Image Specifics — docker-stacks latest documentation")),c.a.createElement("li",null,c.a.createElement("a",{href:"https://spark.apache.org/docs/latest/api/python/pyspark.html"},"pyspark package — PySpark 2.4.0 documentation")),c.a.createElement("li",null,c.a.createElement("a",{href:"https://blog.sicara.com/get-started-pyspark-jupyter-guide-tutorial-ae2fe84f594f"},"Get Started with PySpark and Jupyter Notebook in 3 Minutes")),c.a.createElement("li",null,c.a.createElement("a",{href:"https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-local.html"},"Spark local (pseudo-cluster) · Mastering Apache Spark")))))))};function p(e){return(p="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&"function"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?"symbol":typeof e})(e)}function o(e,a,t,l,n,r,c){try{var s=e[r](c),m=s.value}catch(e){return void t(e)}s.done?a(m):Promise.resolve(m).then(l,n)}function i(e,a){for(var t=0;t<a.length;t++){var l=a[t];l.enumerable=l.enumerable||!1,l.configurable=!0,"value"in l&&(l.writable=!0),Object.defineProperty(e,l.key,l)}}function u(e,a){return!a||"object"!==p(a)&&"function"!=typeof a?function(e){if(void 0===e)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return e}(e):a}function E(e){return(E=Object.setPrototypeOf?Object.getPrototypeOf:function(e){return e.__proto__||Object.getPrototypeOf(e)})(e)}function d(e,a){return(d=Object.setPrototypeOf||function(e,a){return e.__proto__=a,e})(e,a)}t.d(a,"default",function(){return N});var N=function(e){function a(){return function(e,a){if(!(e instanceof a))throw new TypeError("Cannot call a class as a function")}(this,a),u(this,E(a).apply(this,arguments))}var l,r,p;return function(e,a){if("function"!=typeof a&&null!==a)throw new TypeError("Super expression must either be null or a function");e.prototype=Object.create(a&&a.prototype,{constructor:{value:e,writable:!0,configurable:!0}}),a&&d(e,a)}(a,c.a.Component),l=a,r=[{key:"render",value:function(){return c.a.createElement(s.b,{meta:this.props.meta},c.a.createElement(m,null))}}],p=[{key:"getInitialProps",value:function(){var e,a=(e=n.a.mark(function e(){var a,l;return n.a.wrap(function(e){for(;;)switch(e.prev=e.next){case 0:return a=t(39),l=a.entries,e.abrupt("return",{meta:l["blog/2019/01/hello-pyspark"]});case 2:case"end":return e.stop()}},e,this)}),function(){var a=this,t=arguments;return new Promise(function(l,n){var r=e.apply(a,t);function c(e){o(r,l,n,c,s,"next",e)}function s(e){o(r,l,n,c,s,"throw",e)}c(void 0)})});return function(){return a.apply(this,arguments)}}()}],r&&i(l.prototype,r),p&&i(l,p),a}()}},[[386,1,0,2]]]);