(window.webpackJsonp=window.webpackJsonp||[]).push([[22],{Yp5c:function(a,e,t){"use strict";t.d(e,"a",(function(){return j})),t.d(e,"b",(function(){return E}));var n=t("q1tI"),s=t.n(n),l=t("8Kt/"),o=t.n(l),c=t("YFqc"),r=t.n(c),i=t("nOHt"),p=t("TSYQ"),m=t.n(p),u=t("wd/R"),d=t.n(u),h=t("IP2g"),k=t("he5r"),b=s.a.createElement,N=function(a){return b("aside",{className:m()("widget mb-4",a.className)},b("h1",{className:"title font-weight-bold"},a.title),a.children)},y=t("7O5W"),g=t("wHSu"),f=t("8tEE");y.b.add(g.a,g.b,g.c,f.a,f.b);var v=s.a.createElement,w=function(a){return a||"https://yuku.takahashi.coffee".concat(k.a)},x=Object(i.withRouter)((function(a){return v("div",{className:"blogpage container"},v(o.a,null,v("title",null,a.meta.title," - ",k.c),v("meta",{name:"description",content:a.meta.description}),v("meta",{name:"twitter:card",content:"summary"}),v("meta",{name:"twitter:creator",content:"@yuku_t"}),v("meta",{property:"fb:app_id",content:k.b}),v("meta",{property:"og:title",content:"".concat(a.meta.title," - ").concat(k.c)}),v("meta",{property:"og:type",content:"article"}),v("meta",{property:"og:url",content:"https://yuku.takahashi.coffee".concat(a.router.pathname)}),v("meta",{property:"og:image",content:w()}),v("meta",{property:"og:description",content:a.meta.description}),v("link",{rel:"stylesheet",href:"https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/themes/prism.min.css"}),v("link",{rel:"stylesheet",href:"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css"})),v("div",{className:"row"},v("main",{className:m()("col-xl-8",a.className)},v("article",{itemScope:!0,itemType:"http://schema.org/BlogPosting"},v("meta",{itemProp:"author",content:"Yuku Takahashi"}),v("meta",{itemProp:"datePublished",content:a.meta.publishedAt}),a.meta.modifiedAt&&v("meta",{itemProp:"dateModified",content:a.meta.modifiedAt}),v("meta",{itemProp:"image",content:w()}),v("header",{className:"mb-4 header"},v("h1",{className:"headline",itemProp:"headline"},a.meta.title),v("ul",{className:"list-inline text-dark font-weight-light"},v("li",{className:"list-inline-item"},v("span",{className:"ml-1"},d()(a.meta.publishedAt).format("YYYY-MM-DD HH:mm"))),v("li",{className:"list-inline-item"},a.meta.tags.map((function(a,e){return[e>0?",":null,v("span",{key:e,className:"ml-1"},"#",a)]}))))),v("section",{className:"mb-4 body",itemProp:"articleBody"},a.children))),v("div",{className:"col-xl-4"},v("div",{className:"pl-xl-2"},v(N,{title:"About Me"},v("div",null,v("img",{src:k.a,alt:"avatar",className:"avatar rounded-circle mb-4 mx-auto d-block"}),v("p",null,"Software Engineer at FLYWHEEL. Working mainly on recommendation systems in these days. Ex-Qiita CTO.",v(r.a,{href:"/about"},v("a",{href:"/about",style:{marginLeft:"4px"}},"Read more")),"."))),v(N,{title:"Follow"},v("ul",{className:"list-inline icons"},v("li",{className:"list-inline-item"},v("a",{href:"https://twitter.com/yuku_t"},v("span",{className:"fa-stack fa-lg"},v(h.a,{icon:"circle",className:"fa-stack-2x"}),v(h.a,{icon:["fab","twitter"],inverse:!0,className:"fa-stack-1x"})))),v("li",{className:"list-inline-item"},v("a",{href:"https://github.com/yuku"},v("span",{className:"fa-stack fa-lg"},v(h.a,{icon:"circle",className:"fa-stack-2x"}),v(h.a,{icon:["fab","github"],inverse:!0,className:"fa-stack-1x"})))),v("li",{className:"list-inline-item"},v("a",{href:"/static/rss-feed.xml"},v("span",{className:"fa-stack fa-lg"},v(h.a,{icon:"circle",className:"fa-stack-2x"}),v(h.a,{icon:"rss",inverse:!0,className:"fa-stack-1x"}))))))))))})),S=s.a.createElement;function j(a){var e=a.meta,t=a.children;return Object(n.useEffect)((function(){if(e.loadTwitterWidget){var a=document.createElement("script");a.async=!0,a.src="https://platform.twitter.com/widgets.js",a.charset="utf-8",document.body.appendChild(a)}}),[]),S(x,{className:"mdx",meta:e},t)}var I=s.a.createElement,E=function(a){return I(x,{className:"notebook",meta:a.meta},a.children)}},aTI2:function(a,e,t){"use strict";t.r(e);var n=t("o0o1"),s=t.n(n),l=t("HaE+"),o=t("q1tI"),c=t.n(o),r=t("Yp5c"),i=c.a.createElement,p=function(){return i("div",{className:"nb-notebook"},i("div",{className:"nb-worksheet"},i("div",{className:"nb-cell nb-markdown-cell"},i("p",null,i("a",{href:"https://spark.apache.org"},"Apatch Spark")," is an open source distributed programming environment implemented on top of the JVM that has seen ",i("a",{href:"http://fortune.com/2015/09/25/apache-spark-survey/"},"a rapid rise in popularity in recent years"),". I will use Spark through ",i("a",{href:"https://spark.apache.org/docs/latest/api/python/index.html"},"pyspark")," at my next job, so I want to use pyspark, but it's hard to install Spark from scratch because I'm not familiar with the JVM."),i("p",null,"So in this article, I'll use Docker to build Spark and pyspark environments."),i("h2",null,"Set Up an Environment"),i("p",null,"There is a docker image named ",i("a",{href:"https://hub.docker.com/r/jupyter/pyspark-notebook/"},"jupyter/pyspark-notebook")," published by Jupyter Lab. For now, let's pull the latest version:"),i("pre",{className:"language-bash"},i("code",{className:"language-bash"},"docker pull jupyter/pyspark-notebook:87210526f381","\n")),i("p",null,"Run it:"),i("pre",{className:"language-bash"},i("code",{className:"language-bash"},"docker run --rm -w /app -p ",i("span",{className:"token number"},"8888"),":8888 ",i("span",{className:"token punctuation"},"\\"),"\n","    ","--mount ",i("span",{className:"token assign-left variable"},"type"),i("span",{className:"token operator"},"="),"bind,src",i("span",{className:"token operator"},"="),i("span",{className:"token variable"},i("span",{className:"token variable"},"$("),i("span",{className:"token builtin class-name"},"pwd"),i("span",{className:"token variable"},")")),",dst",i("span",{className:"token operator"},"="),"/app ",i("span",{className:"token punctuation"},"\\"),"\n","    ","jupyter/pyspark-notebook:87210526f381","\n")),i("p",null,"Then you will see several messages, among which is the URL. If you access that URL, you will see a Jupyter Notebook that you can use with pyspark:")),i("div",{className:"nb-cell nb-code-cell"},i("div",{className:"nb-input","data-prompt-number":1},i("pre",{className:"language-python"},i("code",{className:"language-python","data-language":"python"},i("span",{className:"token keyword"},"import")," pyspark","\n","pyspark",i("span",{className:"token punctuation"},"."),"version",i("span",{className:"token punctuation"},"."),"__version__"))),i("div",{className:"nb-output","data-prompt-number":1},i("pre",{className:"nb-text-output"},"'2.4.0'"))),i("div",{className:"nb-cell nb-markdown-cell"},i("p",null,"Note that this article is written using Jupyter Notebook, which was launched exactly in this way."),i("h2",null,"Launching a Spark Cluster"),i("p",null,"Spark usually creates a cluster in distributed environment, but creating a distributed cluster in development is not a big deal, so there is ",i("a",{href:"https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-local.html"},"a local mode"),"."),i("p",null,"To start Spark in local mode via pyspark, call ",i("a",{href:"https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.SparkContext"},i("code",null,"pyspark.SparkContext")),":")),i("div",{className:"nb-cell nb-code-cell"},i("div",{className:"nb-input","data-prompt-number":2},i("pre",{className:"language-python"},i("code",{className:"language-python","data-language":"python"},"sc ",i("span",{className:"token operator"},"=")," pyspark",i("span",{className:"token punctuation"},"."),"SparkContext",i("span",{className:"token punctuation"},"("),i("span",{className:"token string"},"'local[*]'"),i("span",{className:"token punctuation"},")"))))),i("div",{className:"nb-cell nb-markdown-cell"},i("p",null,"The string specifies the number available threads:"),i("ul",null,i("li",null,i("code",null,"local")," - 1 thread"),i("li",null,i("code",null,"local[n]")," - ",i("code",null,"n")," threads\uff08",i("code",null,"n")," is a number\uff09"),i("li",null,i("code",null,"local[*]")," - As many threads as available in JVM.\uff08",i("a",{href:"https://docs.oracle.com/javase/8/docs/api/java/lang/Runtime.html#availableProcessors--"},i("code",null,"Runtime.getRuntime.availableProcessors()"))," is used internally\uff09")),i("p",null,"It seems that ",i("code",null,"local[*]")," is commonly used."),i("p",null,"Try to calculate the sum of the numbers from 0 to 10.")),i("div",{className:"nb-cell nb-code-cell"},i("div",{className:"nb-input","data-prompt-number":3},i("pre",{className:"language-python"},i("code",{className:"language-python","data-language":"python"},"rdd ",i("span",{className:"token operator"},"=")," sc",i("span",{className:"token punctuation"},"."),"parallelize",i("span",{className:"token punctuation"},"("),i("span",{className:"token builtin"},"range"),i("span",{className:"token punctuation"},"("),i("span",{className:"token number"},"10"),i("span",{className:"token punctuation"},")"),i("span",{className:"token punctuation"},")"),"\n","rdd",i("span",{className:"token punctuation"},"."),i("span",{className:"token builtin"},"sum"),i("span",{className:"token punctuation"},"("),i("span",{className:"token punctuation"},")")))),i("div",{className:"nb-output","data-prompt-number":3},i("pre",{className:"nb-text-output"},"45"))),i("div",{className:"nb-cell nb-markdown-cell"},i("p",null,"Stop the cluster when you are done using it.")),i("div",{className:"nb-cell nb-code-cell"},i("div",{className:"nb-input","data-prompt-number":4},i("pre",{className:"language-python"},i("code",{className:"language-python","data-language":"python"},"sc",i("span",{className:"token punctuation"},"."),"stop",i("span",{className:"token punctuation"},"("),i("span",{className:"token punctuation"},")"))))),i("div",{className:"nb-cell nb-markdown-cell"},i("h2",null,"Conclusion"),i("p",null,"In this article, I created a pyspark environment using Docker and launched a Spark cluster in a local mode. I don't know much about Spark yet, but I'll try to do more and more things little by little."),i("h2",null,"References"),i("ul",null,i("li",null,i("a",{href:"https://hub.docker.com/r/jupyter/pyspark-notebook/"},"jupyter/pyspark-notebook - Docker Hub")),i("li",null,i("a",{href:"https://jupyter-docker-stacks.readthedocs.io/en/latest/using/specifics.html#apache-spark"},"Image Specifics \u2014 docker-stacks latest documentation")),i("li",null,i("a",{href:"https://spark.apache.org/docs/latest/api/python/pyspark.html"},"pyspark package \u2014 PySpark 2.4.0 documentation")),i("li",null,i("a",{href:"https://blog.sicara.com/get-started-pyspark-jupyter-guide-tutorial-ae2fe84f594f"},"Get Started with PySpark and Jupyter Notebook in 3 Minutes")),i("li",null,i("a",{href:"https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-local.html"},"Spark local (pseudo-cluster) \xb7 Mastering Apache Spark"))))))},m=c.a.createElement,u=function(a){var e=a.meta;return m(r.b,{meta:e},m(p,null))};u.getInitialProps=Object(l.a)(s.a.mark((function a(){var e,n;return s.a.wrap((function(a){for(;;)switch(a.prev=a.next){case 0:return e=t("n1xW"),n=e.entries,a.abrupt("return",{meta:n["blog/2019/01/hello-pyspark"]});case 2:case"end":return a.stop()}}),a)})));e.default=u},eesI:function(a,e,t){(window.__NEXT_P=window.__NEXT_P||[]).push(["/blog/2019/01/hello-pyspark",function(){return t("aTI2")}])}},[["eesI",0,1,3,7,6,2,5,4]]]);