<!DOCTYPE html><html prefix="og: http://ogp.me/ns#"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><link rel="apple-touch-icon" sizes="57x57" href="/static/icons/apple-icon-57x57.png"/><link rel="apple-touch-icon" sizes="60x60" href="/static/icons/apple-icon-60x60.png"/><link rel="apple-touch-icon" sizes="72x72" href="/static/icons/apple-icon-72x72.png"/><link rel="apple-touch-icon" sizes="76x76" href="/static/icons/apple-icon-76x76.png"/><link rel="apple-touch-icon" sizes="114x114" href="/static/icons/apple-icon-114x114.png"/><link rel="apple-touch-icon" sizes="120x120" href="/static/icons/apple-icon-120x120.png"/><link rel="apple-touch-icon" sizes="144x144" href="/static/icons/apple-icon-144x144.png"/><link rel="apple-touch-icon" sizes="152x152" href="/static/icons/apple-icon-152x152.png"/><link rel="apple-touch-icon" sizes="180x180" href="/static/icons/apple-icon-180x180.png"/><link rel="icon" type="image/png" sizes="192x192" href="/static/icons/android-icon-192x192.png"/><link rel="icon" type="image/png" sizes="32x32" href="/static/icons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/static/icons/favicon-96x96.png"/><link rel="icon" type="image/png" sizes="16x16" href="/static/icons/favicon-16x16.png"/><link rel="icon" href="/static/icons/favicon.ico"/><link rel="manifest" href="/static/config/manifest.json"/><meta name="msapplication-TileColor" content="#00BCD4"/><meta name="msapplication-TileImage" content="/static/icons/ms-icon-144x144.png"/><meta name="msapplication-config" content="/static/config/browserconfig.xml"/><meta name="google-site-verification" content="uoCr1A890A-K8B7GkFUvLlQ5ihZlFyR6gzvt4F-62u0"/><link href="https://fonts.googleapis.com/css?family=Noto+Sans+JP:300,400,700|Damion" rel="stylesheet"/><script defer="" src="https://use.fontawesome.com/releases/v5.6.3/js/all.js"></script><title>Docker を使って pyspark に入門する - yt coffee</title><meta name="description" content="Jupyter Lab が提供している Docker イメージで作った動作環境を使って pyspark に入門します。"/><meta name="twitter:card" content="summary"/><meta name="twitter:creator" content="@yuku_t"/><meta property="fb:app_id" content="1188125924685915"/><meta property="og:title" content="Docker を使って pyspark に入門する - yt coffee"/><meta property="og:type" content="article"/><meta property="og:url" content="https://yuku.takahashi.coffee/blog/2019/01/hello-pyspark"/><meta property="og:image" content="https://yuku.takahashi.coffee/static/images/haniwa.jpg"/><meta property="og:description" content="Jupyter Lab が提供している Docker イメージで作った動作環境を使って pyspark に入門します。"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/themes/prism.min.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css"/><meta name="next-head-count" content="35"/><link rel="preload" href="/_next/static/V8c_JJdwgtnUkT5ePxKkO/pages/blog/2019/01/hello-pyspark.js" as="script"/><link rel="preload" href="/_next/static/V8c_JJdwgtnUkT5ePxKkO/pages/_app.js" as="script"/><link rel="preload" href="/_next/static/runtime/webpack-4b444dab214c6491079c.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.8a9c37cbc39ec4f25df5.js" as="script"/><link rel="preload" href="/_next/static/runtime/main-1d4496b03403c49f20d7.js" as="script"/><link rel="preload" href="/_next/static/chunks/styles.05e4d3a00f0c42d0eddc.js" as="script"/><link rel="stylesheet" href="/_next/static/css/commons.3417e405.chunk.css"/><link rel="stylesheet" href="/_next/static/css/styles.d251c2cb.chunk.css"/></head><body><div id="__next"><div class="layout mx-md-auto d-md-flex"><nav class="topbar-mobile d-flex justify-content-between d-md-none py-4 px-3"><a href="/" class="brand">yt coffee</a><button class="border-0 bg-transparent text-black-50"><i class="fas fa-bars"></i></button></nav><div class="side-menu d-md-block px-3 p-lg-5 py-4"><div class="side-menu-inner"><a href="/" class="brand">yt coffee</a><p class="text-muted font-weight-light pt-1"><small>Study hard, play harder.</small></p><ul class="list list-unstyled"><li class=""><a href="/">Home</a></li><li class=""><a href="/about">About</a></li><li class=""><a href="/resume">Resume</a></li></ul></div></div><div class="flex-md-grow-1 bg-white px-sm-3 pt-lg-5 py-4 overflow-hidden"><div class="blogpage container"><div class="row"><main class="col-xl-8 notebook"><article itemscope="" itemType="http://schema.org/BlogPosting"><meta itemProp="author" content="Yuku Takahashi"/><meta itemProp="datePublished" content="2019-01-16T20:50:00+09:00"/><meta itemProp="dateModified" content="2019-01-17T17:54:00+09:00"/><meta itemProp="image" content="https://yuku.takahashi.coffee/static/images/haniwa.jpg"/><header class="mb-4 header"><h1 class="headline" itemProp="headline">Docker を使って pyspark に入門する</h1><ul class="list-inline text-dark font-weight-light"><li class="list-inline-item"><span class="ml-1">2019-01-16 11:50</span></li><li class="list-inline-item"><span class="ml-1">#<!-- -->pyspark</span></li></ul></header><section class="mb-4 body" itemProp="articleBody"><div class="nb-notebook"><div class="nb-worksheet"><div class="nb-cell nb-markdown-cell"><p><a href="https://spark.apache.org">Apatch Spark</a> は JVM 上に実装されたオープンソースの分散処理プログラミング環境で、<a href="http://fortune.com/2015/09/25/apache-spark-survey/">近年急速な盛り上がりを見せています</a>。 今後 <a href="https://spark.apache.org/docs/latest/api/python/index.html">pyspark</a> を通じて Spark を使う予定なので、試しに触ってみたいのですが、いかんせん JVM に慣れていないこともあって Spark のインストールから始めると大変です。</p><p>そこでこの記事では Docker を使って Spark と pyspark の環境を構築します。</p><h2>環境を用意する</h2><p>Jupyter Lab が公開している <a href="https://hub.docker.com/r/jupyter/pyspark-notebook/">jupyter/pyspark-notebook</a> というズバリな Docker イメージがあるのでこれを使います。さしあたり最新バージョンをとってきました:</p><pre class="language-bash"><code class="language-bash">docker pull jupyter/pyspark-notebook:87210526f381<!-- -->
</code></pre><p>起動します:</p><pre class="language-bash"><code class="language-bash">docker run --rm -w /app -p <span class="token number">8888</span>:8888 <span class="token punctuation">\</span>
<!-- -->    <!-- -->--mount <span class="token assign-left variable">type</span><span class="token operator">=</span>bind,src<span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span><span class="token builtin class-name">pwd</span><span class="token variable">)</span></span>,dst<span class="token operator">=</span>/app <span class="token punctuation">\</span>
<!-- -->    <!-- -->jupyter/pyspark-notebook:87210526f381<!-- -->
</code></pre><p>すると何やらログが表示される中に URL が表示されるので、その URL にアクセスすれば pyspark が使える Jupyter Notebook が表示されます。簡単ですね。</p></div><div class="nb-cell nb-code-cell"><div class="nb-input" data-prompt-number="1"><pre class="language-python"><code class="language-python" data-language="python"><span class="token keyword">import</span> pyspark<!-- -->
<!-- -->pyspark<span class="token punctuation">.</span>version<span class="token punctuation">.</span>__version__</code></pre></div><div class="nb-output" data-prompt-number="1"><pre class="nb-text-output">&#x27;2.4.0&#x27;</pre></div></div><div class="nb-cell nb-markdown-cell"><p>ちなみにこの記事はまさにこうして起動した Jupyter Notebook を使って書かれています。</p><h2>Spark クラスタを起動する</h2><p>Spark は通常クラスタを作って分散処理を行いますが、開発段階からクラスタを作るのは大変なので <a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-local.html">local mode</a> が用意されています。</p><p>pyspark から local mode で Spark を起動するには <a href="https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.SparkContext"><code>pyspark.SparkContext</code></a> を実行します:</p></div><div class="nb-cell nb-code-cell"><div class="nb-input" data-prompt-number="2"><pre class="language-python"><code class="language-python" data-language="python">sc <span class="token operator">=</span> pyspark<span class="token punctuation">.</span>SparkContext<span class="token punctuation">(</span><span class="token string">&#x27;local[*]&#x27;</span><span class="token punctuation">)</span></code></pre></div></div><div class="nb-cell nb-markdown-cell"><p>渡している文字列は利用可能スレッド数を意味していて:</p><ul><li><code>local</code> - 1 スレッドのみ使う</li><li><code>local[n]</code> - <code>n</code> スレッド使う（<code>n</code> は実際には数字が入る）</li><li><code>local[*]</code> - JVM で使えるプロセッサーの数だけスレッドを使う（内部では <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Runtime.html#availableProcessors--"><code>Runtime.getRuntime.availableProcessors()</code></a> を使っているらしい）</li></ul><p>ということを表しています。一般的には <code>local[*]</code> が使われるようです。</p><p>試しに 0 から 10 までの数字の合計を計算してみます。</p></div><div class="nb-cell nb-code-cell"><div class="nb-input" data-prompt-number="3"><pre class="language-python"><code class="language-python" data-language="python">rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<!-- -->rdd<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre></div><div class="nb-output" data-prompt-number="3"><pre class="nb-text-output">45</pre></div></div><div class="nb-cell nb-markdown-cell"><p>使い終わったら停止します。</p></div><div class="nb-cell nb-code-cell"><div class="nb-input" data-prompt-number="4"><pre class="language-python"><code class="language-python" data-language="python">sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre></div></div><div class="nb-cell nb-markdown-cell"><h2>おわりに</h2><p>この記事では Docker を使って pyspark 環境を作り、実際に Spark クラスタを起動してみました。Spark のことはまだまだ全然分かりませんが少しずつできることを増やしていこうと思います。</p><h2>参考</h2><ul><li><a href="https://hub.docker.com/r/jupyter/pyspark-notebook/">jupyter/pyspark-notebook - Docker Hub</a></li><li><a href="https://jupyter-docker-stacks.readthedocs.io/en/latest/using/specifics.html#apache-spark">Image Specifics — docker-stacks latest documentation</a></li><li><a href="https://spark.apache.org/docs/latest/api/python/pyspark.html">pyspark package — PySpark 2.4.0 documentation</a></li><li><a href="https://blog.sicara.com/get-started-pyspark-jupyter-guide-tutorial-ae2fe84f594f">Get Started with PySpark and Jupyter Notebook in 3 Minutes</a></li><li><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-local.html">Spark local (pseudo-cluster) · Mastering Apache Spark</a></li></ul></div></div></div></section></article></main><div class="col-xl-4"><div class="pl-xl-2"><aside class="widget mb-4"><h1 class="title font-weight-bold">About Me</h1><div><img src="/static/images/haniwa.jpg" alt="avatar" class="avatar rounded-circle mb-4 mx-auto d-block"/><p>FLYWHEEL ソフトウェアエンジニア。ex-Qiita CTO。最近は専らレコメンドシステムを作っています。<a href="/about">Read more</a>.</p></div></aside><aside class="widget mb-4"><h1 class="title font-weight-bold">Follow</h1><ul class="list-inline icons"><li class="list-inline-item"><a href="https://twitter.com/yuku_t"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i><i class="fab fa-twitter fa-stack-1x fa-inverse"></i></span></a></li><li class="list-inline-item"><a href="https://github.com/yuku"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i><i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li></ul></aside></div></div></div></div><footer class="text-center mt-4"><p class="mb-0 text-dark"><small>© Yuku Takahashi <!-- -->2019<!-- --> - This work is licensed under a<!-- --> <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0 </a></small></p></footer></div></div></div><script id="__NEXT_DATA__" type="application/json">{"dataManager":"[]","props":{"pageProps":{"meta":{"description":"Jupyter Lab が提供している Docker イメージで作った動作環境を使って pyspark に入門します。","format":"ipynb","modifiedAt":"2019-01-17T17:54:00+09:00","publishedAt":"2019-01-16T20:50:00+09:00","tags":["pyspark"],"title":"Docker を使って pyspark に入門する"}}},"page":"/blog/2019/01/hello-pyspark","query":{},"buildId":"V8c_JJdwgtnUkT5ePxKkO","nextExport":true}</script><script async="" data-next-page="/blog/2019/01/hello-pyspark" src="/_next/static/V8c_JJdwgtnUkT5ePxKkO/pages/blog/2019/01/hello-pyspark.js"></script><script async="" data-next-page="/_app" src="/_next/static/V8c_JJdwgtnUkT5ePxKkO/pages/_app.js"></script><script src="/_next/static/runtime/webpack-4b444dab214c6491079c.js" async=""></script><script src="/_next/static/chunks/commons.8a9c37cbc39ec4f25df5.js" async=""></script><script src="/_next/static/runtime/main-1d4496b03403c49f20d7.js" async=""></script><script src="/_next/static/chunks/styles.05e4d3a00f0c42d0eddc.js" async=""></script></body></html>