<!DOCTYPE html><html prefix="og: http://ogp.me/ns#"><head><meta charSet="utf-8" class="next-head"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" class="next-head"/><link rel="apple-touch-icon" sizes="57x57" href="/static/icons/apple-icon-57x57.png" class="next-head"/><link rel="apple-touch-icon" sizes="60x60" href="/static/icons/apple-icon-60x60.png" class="next-head"/><link rel="apple-touch-icon" sizes="72x72" href="/static/icons/apple-icon-72x72.png" class="next-head"/><link rel="apple-touch-icon" sizes="76x76" href="/static/icons/apple-icon-76x76.png" class="next-head"/><link rel="apple-touch-icon" sizes="114x114" href="/static/icons/apple-icon-114x114.png" class="next-head"/><link rel="apple-touch-icon" sizes="120x120" href="/static/icons/apple-icon-120x120.png" class="next-head"/><link rel="apple-touch-icon" sizes="144x144" href="/static/icons/apple-icon-144x144.png" class="next-head"/><link rel="apple-touch-icon" sizes="152x152" href="/static/icons/apple-icon-152x152.png" class="next-head"/><link rel="apple-touch-icon" sizes="180x180" href="/static/icons/apple-icon-180x180.png" class="next-head"/><link rel="icon" type="image/png" sizes="192x192" href="/static/icons/android-icon-192x192.png" class="next-head"/><link rel="icon" type="image/png" sizes="32x32" href="/static/icons/favicon-32x32.png" class="next-head"/><link rel="icon" type="image/png" sizes="96x96" href="/static/icons/favicon-96x96.png" class="next-head"/><link rel="icon" type="image/png" sizes="16x16" href="/static/icons/favicon-16x16.png" class="next-head"/><link rel="icon" href="/static/icons/favicon.ico" class="next-head"/><link rel="manifest" href="/static/config/manifest.json" class="next-head"/><meta name="msapplication-TileColor" content="#00BCD4" class="next-head"/><meta name="msapplication-TileImage" content="/static/icons/ms-icon-144x144.png" class="next-head"/><meta name="msapplication-config" content="/static/config/browserconfig.xml" class="next-head"/><meta name="google-site-verification" content="uoCr1A890A-K8B7GkFUvLlQ5ihZlFyR6gzvt4F-62u0" class="next-head"/><link href="https://fonts.googleapis.com/css?family=Noto+Sans+JP:300,400,700" rel="stylesheet" class="next-head"/><script defer="" src="https://use.fontawesome.com/releases/v5.6.3/js/all.js" class="next-head"></script><title class="next-head">Docker を使って pyspark に入門する - SELECT * FROM life;</title><meta name="description" content="Jupyter Lab が提供している Docker イメージで作った動作環境を使って pyspark に入門します。" class="next-head"/><meta name="twitter:card" content="summary" class="next-head"/><meta name="twitter:creator" content="@yuku_t" class="next-head"/><meta property="fb:app_id" content="1188125924685915" class="next-head"/><meta property="og:title" content="Docker を使って pyspark に入門する - SELECT * FROM life;" class="next-head"/><meta property="og:type" content="article" class="next-head"/><meta property="og:url" content="https://yuku.takahashi.coffee/blog/2019/01/hello-pyspark" class="next-head"/><meta property="og:image" content="https://yuku.takahashi.coffee/static/images/haniwa.jpg" class="next-head"/><meta property="og:description" content="Jupyter Lab が提供している Docker イメージで作った動作環境を使って pyspark に入門します。" class="next-head"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/themes/prism.min.css" class="next-head"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" class="next-head"/><link rel="preload" href="/_next/static/lkECmSZnRWd2buo~7yJAS/pages/blog/2019/01/hello-pyspark.js" as="script"/><link rel="preload" href="/_next/static/lkECmSZnRWd2buo~7yJAS/pages/_app.js" as="script"/><link rel="preload" href="/_next/static/lkECmSZnRWd2buo~7yJAS/pages/_error.js" as="script"/><link rel="preload" href="/_next/static/runtime/webpack-89179faa512dd01fbb62.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.86e96eb0d86261fc5c67.js" as="script"/><link rel="preload" href="/_next/static/chunks/styles.50279a8a500b414c8fac.js" as="script"/><link rel="preload" href="/_next/static/runtime/main-a017c8f5537a6fd69b3b.js" as="script"/><link rel="stylesheet" href="/_next/static/css/commons.e96421d5.chunk.css"/><link rel="stylesheet" href="/_next/static/css/styles.a57ba0c1.chunk.css"/></head><body><div id="__next"><div class="layout mx-md-auto d-md-flex"><nav class="topbar-mobile d-flex justify-content-between d-md-none py-4 px-3"><a href="/" class="brand">SELECT * FROM life;</a><button class="border-0 bg-transparent text-black-50"><i class="fas fa-bars"></i></button></nav><div class="side-menu d-md-block px-3 p-lg-5 py-4"><div class="side-menu-inner"><a href="/" class="brand">SELECT * FROM life;</a><p class="text-muted font-weight-light pt-1"><small>Study hard, play harder.</small></p><ul class="list list-unstyled"><li class=""><a href="/">Home</a></li><li class=""><a href="/about">About</a></li><li class=""><a href="/resume">Resume</a></li></ul></div></div><div class="flex-md-grow-1 bg-white px-sm-3 pt-lg-5 py-4 overflow-hidden"><div class="blogpage container"><div class="row"><main class="col-xl-8 notebook"><article itemscope="" itemType="http://schema.org/BlogPosting"><meta itemProp="author" content="Yuku Takahashi"/><meta itemProp="datePublished" content="2019-01-16T20:50:00+09:00"/><meta itemProp="dateModified" content="2019-01-17T17:54:00+09:00"/><meta itemProp="image" content="https://yuku.takahashi.coffee/static/images/haniwa.jpg"/><header class="mb-4 header"><h1 class="headline" itemProp="headline">Docker を使って pyspark に入門する</h1><ul class="list-inline text-dark font-weight-light"><li class="list-inline-item"><i class="fas fa-calendar-day fa-fw"></i><span class="ml-1">2019-01-16 11:50</span></li><li class="list-inline-item"><i class="fas fa-tags fa-fw"></i><span class="ml-1">pyspark</span></li></ul></header><section class="mb-4 body" itemProp="articleBody"><div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p><a href="https://spark.apache.org">Apatch Spark</a> は JVM 上に実装されたオープンソースの分散処理プログラミング環境で、<a href="http://fortune.com/2015/09/25/apache-spark-survey/">近年急速な盛り上がりを見せています</a>。 今後 <a href="https://spark.apache.org/docs/latest/api/python/index.html">pyspark</a> を通じて Spark を使う予定なので、試しに触ってみたいのですが、いかんせん JVM に慣れていないこともあって Spark のインストールから始めると大変です。</p><p>そこでこの記事では Docker を使って Spark と pyspark の環境を構築します。</p><h2 id="環境を用意する">環境を用意する<a class="anchor-link" href="#環境を用意する">¶</a></h2><p>Jupyter Lab が公開している <a href="https://hub.docker.com/r/jupyter/pyspark-notebook/">jupyter/pyspark-notebook</a> というズバリな Docker イメージがあるのでこれを使います。さしあたり最新バージョンをとってきました:</p><div class="highlight"><pre><span></span>docker pull jupyter/pyspark-notebook:87210526f381<!-- -->
</pre></div><p>起動します:</p><div class="highlight"><pre><span></span>docker run --rm -w /app -p <span class="m">8888</span>:8888 <span class="se">\</span>
<!-- -->    <!-- -->--mount <span class="nv">type</span><span class="o">=</span>bind,src<span class="o">=</span><span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>,dst<span class="o">=</span>/app <span class="se">\</span>
<!-- -->    <!-- -->jupyter/pyspark-notebook:87210526f381<!-- -->
</pre></div><p>すると何やらログが表示される中に URL が表示されるので、その URL にアクセスすれば pyspark が使える Jupyter Notebook が表示されます。簡単ですね。</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In [1]:</div><div class="inner_cell"><div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pyspark</span>
<span class="n">pyspark</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">__version__</span>
</pre></div></div></div></div><div class="output_wrapper"><div class="output"><div class="output_area"><div class="prompt output_prompt">Out[1]:</div><div class="output_text output_subarea output_execute_result"><pre>&#x27;2.4.0&#x27;</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>ちなみにこの記事はまさにこうして起動した Jupyter Notebook を使って書かれています。</p><h2 id="Spark-クラスタを起動する">Spark クラスタを起動する<a class="anchor-link" href="#Spark-クラスタを起動する">¶</a></h2><p>Spark は通常クラスタを作って分散処理を行いますが、開発段階からクラスタを作るのは大変なので <a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-local.html">local mode</a> が用意されています。</p><p>pyspark から local mode で Spark を起動するには <a href="https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.SparkContext"><code>pyspark.SparkContext</code></a> を実行します:</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In [2]:</div><div class="inner_cell"><div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">sc</span> <span class="o">=</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">SparkContext</span><span class="p">(</span><span class="s1">&#x27;local[*]&#x27;</span><span class="p">)</span>
</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>渡している文字列は利用可能スレッド数を意味していて:</p><ul><li><code>local</code> - 1 スレッドのみ使う</li><li><code>local[n]</code> - <code>n</code> スレッド使う（<code>n</code> は実際には数字が入る）</li><li><code>local[*]</code> - JVM で使えるプロセッサーの数だけスレッドを使う（内部では <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Runtime.html#availableProcessors--"><code>Runtime.getRuntime.availableProcessors()</code></a> を使っているらしい）</li></ul><p>ということを表しています。一般的には <code>local[*]</code> が使われるようです。</p><p>試しに 0 から 10 までの数字の合計を計算してみます。</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In [3]:</div><div class="inner_cell"><div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">rdd</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="n">rdd</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div></div></div></div><div class="output_wrapper"><div class="output"><div class="output_area"><div class="prompt output_prompt">Out[3]:</div><div class="output_text output_subarea output_execute_result"><pre>45</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><p>使い終わったら停止します。</p></div></div></div><div class="cell border-box-sizing code_cell rendered"><div class="input"><div class="prompt input_prompt">In [4]:</div><div class="inner_cell"><div class="input_area"><div class=" highlight hl-ipython3"><pre><span></span><span class="n">sc</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
</pre></div></div></div></div></div><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="text_cell_render border-box-sizing rendered_html"><h2 id="おわりに">おわりに<a class="anchor-link" href="#おわりに">¶</a></h2><p>この記事では Docker を使って pyspark 環境を作り、実際に Spark クラスタを起動してみました。Spark のことはまだまだ全然分かりませんが少しずつできることを増やしていこうと思います。</p><h2 id="参考">参考<a class="anchor-link" href="#参考">¶</a></h2><ul><li><a href="https://hub.docker.com/r/jupyter/pyspark-notebook/">jupyter/pyspark-notebook - Docker Hub</a></li><li><a href="https://jupyter-docker-stacks.readthedocs.io/en/latest/using/specifics.html#apache-spark">Image Specifics — docker-stacks latest documentation</a></li><li><a href="https://spark.apache.org/docs/latest/api/python/pyspark.html">pyspark package — PySpark 2.4.0 documentation</a></li><li><a href="https://blog.sicara.com/get-started-pyspark-jupyter-guide-tutorial-ae2fe84f594f">Get Started with PySpark and Jupyter Notebook in 3 Minutes</a></li><li><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-local.html">Spark local (pseudo-cluster) · Mastering Apache Spark</a></li></ul></div></div></div></div></section></article></main><div class="col-xl-4"><div class="pl-xl-2"><aside class="widget mb-4"><h1 class="title font-weight-bold">About Me</h1><div><img src="/static/images/haniwa.jpg" alt="avatar" class="avatar rounded-circle mb-4 mx-auto d-block"/><p>Increments 社最初の従業員として Qiita を開発したり CTO やったりしていました。現在有給消化中。<a href="/about">もっと読む</a></p></div></aside><aside class="widget mb-4"><h1 class="title font-weight-bold">Follow</h1><ul class="list-inline icons"><li class="list-inline-item"><a href="https://twitter.com/yuku_t"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i><i class="fab fa-twitter fa-stack-1x fa-inverse"></i></span></a></li><li class="list-inline-item"><a href="https://github.com/yuku"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i><i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li></ul></aside></div></div></div></div><footer class="text-center mt-4"><p class="mb-0 text-dark"><small>© Yuku Takahashi <!-- -->2019<!-- --> - This work is licensed under a<!-- --> <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0 </a></small></p></footer></div></div></div><script>__NEXT_DATA__ = {"props":{"pageProps":{"meta":{"description":"Jupyter Lab が提供している Docker イメージで作った動作環境を使って pyspark に入門します。","format":"ipynb","modifiedAt":"2019-01-17T17:54:00+09:00","publishedAt":"2019-01-16T20:50:00+09:00","tags":["pyspark"],"title":"Docker を使って pyspark に入門する"}}},"page":"/blog/2019/01/hello-pyspark","query":{},"buildId":"lkECmSZnRWd2buo~7yJAS","nextExport":true};__NEXT_LOADED_PAGES__=[];__NEXT_REGISTER_PAGE=function(r,f){__NEXT_LOADED_PAGES__.push([r, f])}</script><script async="" id="__NEXT_PAGE__/blog/2019/01/hello-pyspark" src="/_next/static/lkECmSZnRWd2buo~7yJAS/pages/blog/2019/01/hello-pyspark.js"></script><script async="" id="__NEXT_PAGE__/_app" src="/_next/static/lkECmSZnRWd2buo~7yJAS/pages/_app.js"></script><script async="" id="__NEXT_PAGE__/_error" src="/_next/static/lkECmSZnRWd2buo~7yJAS/pages/_error.js"></script><script src="/_next/static/runtime/webpack-89179faa512dd01fbb62.js" async=""></script><script src="/_next/static/chunks/commons.86e96eb0d86261fc5c67.js" async=""></script><script src="/_next/static/chunks/styles.50279a8a500b414c8fac.js" async=""></script><script src="/_next/static/runtime/main-a017c8f5537a6fd69b3b.js" async=""></script></body></html>